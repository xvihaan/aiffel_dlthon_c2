{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f6c924f9",
   "metadata": {},
   "source": [
    "# 0. 버전확인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7634cf25",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.6.0\n"
     ]
    }
   ],
   "source": [
    "import tensorflow\n",
    "\n",
    "print(tensorflow.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cddf7c91",
   "metadata": {},
   "source": [
    "# Step 1. 데이터 수집하기\n",
    "### 한국어 챗봇 데이터는 tunib에서 제공하는 데이터셋으로, 멀티턴 대화 형식의 데이터로 구성\n",
    "\n",
    "Cloud shell에서 아래 명령어를 입력해 주세요.\n",
    "\n",
    "$ mkdir -p ~/aiffel/dktc\n",
    "$ ln -s ~/data/ ~/aiffel/dktc"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "872744dc",
   "metadata": {},
   "source": [
    "# Step 2. 데이터 전처리하기\n",
    "### 영어 데이터와는 전혀 다른 데이터인 만큼 영어 데이터에 사용했던 전처리와 일부 동일한 전처리도 필요하겠지만 전체적으로는 다른 전처리를 수행"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cb34ed99",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=3\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import re\n",
    "import matplotlib.pyplot as plt\n",
    "from bs4 import BeautifulSoup \n",
    "from tensorflow.keras.preprocessing.text import Tokenizer \n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "import urllib.request\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=UserWarning, module='bs4')\n",
    "\n",
    "print('=3')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "592d898b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>idx</th>\n",
       "      <th>class</th>\n",
       "      <th>conversation</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>협박 대화</td>\n",
       "      <td>지금 너 스스로를 죽여달라고 애원하는 것인가?\\n 아닙니다. 죄송합니다.\\n 죽을 ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>협박 대화</td>\n",
       "      <td>길동경찰서입니다.\\n9시 40분 마트에 폭발물을 설치할거다.\\n네?\\n똑바로 들어 ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>기타 괴롭힘 대화</td>\n",
       "      <td>너 되게 귀여운거 알지? 나보다 작은 남자는 첨봤어.\\n그만해. 니들 놀리는거 재미...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>갈취 대화</td>\n",
       "      <td>어이 거기\\n예??\\n너 말이야 너. 이리 오라고\\n무슨 일.\\n너 옷 좋아보인다?...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>갈취 대화</td>\n",
       "      <td>저기요 혹시 날이 너무 뜨겁잖아요? 저희 회사에서 이 선크림 파는데 한 번 손등에 ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   idx      class                                       conversation\n",
       "0    0      협박 대화  지금 너 스스로를 죽여달라고 애원하는 것인가?\\n 아닙니다. 죄송합니다.\\n 죽을 ...\n",
       "1    1      협박 대화  길동경찰서입니다.\\n9시 40분 마트에 폭발물을 설치할거다.\\n네?\\n똑바로 들어 ...\n",
       "2    2  기타 괴롭힘 대화  너 되게 귀여운거 알지? 나보다 작은 남자는 첨봤어.\\n그만해. 니들 놀리는거 재미...\n",
       "3    3      갈취 대화  어이 거기\\n예??\\n너 말이야 너. 이리 오라고\\n무슨 일.\\n너 옷 좋아보인다?...\n",
       "4    4      갈취 대화  저기요 혹시 날이 너무 뜨겁잖아요? 저희 회사에서 이 선크림 파는데 한 번 손등에 ..."
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data_path =\"aiffel/dktc/train.csv\"\n",
    "train_data = pd.read_csv(train_data_path)\n",
    "train_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cae89b50",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = train_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a21eb0c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "샘플 개수: 12092\n"
     ]
    }
   ],
   "source": [
    "num_samples = len(data)\n",
    "print(\"샘플 개수:\", num_samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "944c9de5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "중복된 데이터: {}\n"
     ]
    }
   ],
   "source": [
    "# 중복 확인\n",
    "from collections import Counter\n",
    "\n",
    "data_counts = Counter(data)\n",
    "duplicates = {item: count for item, count in data_counts.items() if count > 1}\n",
    "\n",
    "print(\"중복된 데이터:\", duplicates)  # {1: 2} (1이 2번 등장)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "cd2db021",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "class 열에 누락값이 있습니까? False\n",
      "idx 열에 누락값이 있습니까? False\n"
     ]
    }
   ],
   "source": [
    "# 'class' 열과 'idx' 열에 누락값 확인\n",
    "missing_class = data['class'].isnull().any()\n",
    "missing_idx = data['idx'].isnull().any()\n",
    "\n",
    "print(\"class 열에 누락값이 있습니까?\", missing_class)  # True (누락값 있음)\n",
    "print(\"idx 열에 누락값이 있습니까?\", missing_idx)      # True (누락값 있음)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d5c26550",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                        conversation  \\\n",
      "0  지금 너 스스로를 죽여달라고 애원하는 것인가?\\n 아닙니다. 죄송합니다.\\n 죽을 ...   \n",
      "1  길동경찰서입니다.\\n9시 40분 마트에 폭발물을 설치할거다.\\n네?\\n똑바로 들어 ...   \n",
      "2  너 되게 귀여운거 알지? 나보다 작은 남자는 첨봤어.\\n그만해. 니들 놀리는거 재미...   \n",
      "3  어이 거기\\n예??\\n너 말이야 너. 이리 오라고\\n무슨 일.\\n너 옷 좋아보인다?...   \n",
      "4  저기요 혹시 날이 너무 뜨겁잖아요? 저희 회사에서 이 선크림 파는데 한 번 손등에 ...   \n",
      "\n",
      "                              conversation_processed  \\\n",
      "0  지금 너 스스로를 죽여달라고 애원하는 것인가 ? 아닙니다 . 죄송합니다 . 죽을 거...   \n",
      "1  길동경찰서입니다 . 9시 40분 마트에 폭발물을 설치할거다 . 네 ? 똑바로 들어 ...   \n",
      "2  너 되게 귀여운거 알지 ? 나보다 작은 남자는 첨봤어 . 그만해 . 니들 놀리는거 ...   \n",
      "3  어이 거기 예 ? ? 너 말이야 너 . 이리 오라고 무슨 일 . 너 옷 좋아보인다 ...   \n",
      "4  저기요 혹시 날이 너무 뜨겁잖아요 ? 저희 회사에서 이 선크림 파는데 한 번 손등에...   \n",
      "\n",
      "                               conversation_filtered  \n",
      "0  지금 너 스스로를 죽여달라고 애원하는 것인가 ? 아닙니다 . 죄송합니다 . 죽을 거...  \n",
      "1  길동경찰서입니다 . 9시 40분 마트에 폭발물을 설치할거다 . 네 ? 똑바로 들어 ...  \n",
      "2  너 되게 귀여운거 알지 ? 나보다 작은 남자는 첨봤어 . 그만해 . 니들 놀리는거 ...  \n",
      "3  어이 거기 예 ? ? 너 말이야 너 . 이리 오라고 무슨 일 . 너 옷 좋아보인다 ...  \n",
      "4  저기요 혹시 날이 너무 뜨겁잖아요 ? 저희 회사에서 선크림 파는데 한 번 손등에 발...  \n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "# 한글 불용어 목록\n",
    "stopwords = [\n",
    "    \"이\", \"그\", \"저\", \"가\", \"을\", \"를\", \"에\", \"의\", \"와\", \"과\", \"들\"\n",
    "]\n",
    "\n",
    "def preprocess_korean_text(data):\n",
    "    processed_texts = []\n",
    "    \n",
    "    for sentence in data:\n",
    "        # 구두점 처리\n",
    "        sentence = re.sub(r\"([?.!,])\", r\" \\1 \", sentence)\n",
    "        \n",
    "        # 중복 공백 제거\n",
    "        sentence = re.sub(r'\\s+', ' ', sentence)\n",
    "        \n",
    "        # 양쪽 공백 제거\n",
    "        sentence = sentence.strip()\n",
    "        \n",
    "        processed_texts.append(sentence)\n",
    "    \n",
    "    return processed_texts\n",
    "\n",
    "def remove_stopwords(data, stopwords):\n",
    "    filtered_texts = []\n",
    "    \n",
    "    for sentence in data:\n",
    "        # 텍스트를 공백으로 분리하여 단어 리스트 생성\n",
    "        words = sentence.split()\n",
    "        \n",
    "        # 불용어가 아닌 단어만 필터링\n",
    "        filtered_words = [word for word in words if word not in stopwords]\n",
    "        \n",
    "        # 필터링된 단어를 다시 문자열로 결합\n",
    "        filtered_texts.append(' '.join(filtered_words))\n",
    "    \n",
    "    return filtered_texts\n",
    "\n",
    "\n",
    "# conversation 열에 대해서만 전처리 및 불용어 제거 적용\n",
    "data['conversation_processed'] = preprocess_korean_text(data['conversation'])\n",
    "data['conversation_filtered'] = remove_stopwords(data['conversation_processed'], stopwords)\n",
    "\n",
    "# 결과 확인\n",
    "print(data[['conversation', 'conversation_processed', 'conversation_filtered']].head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "bc61a93a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>idx</th>\n",
       "      <th>class</th>\n",
       "      <th>conversation</th>\n",
       "      <th>conversation_processed</th>\n",
       "      <th>conversation_filtered</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>협박 대화</td>\n",
       "      <td>지금 너 스스로를 죽여달라고 애원하는 것인가?\\n 아닙니다. 죄송합니다.\\n 죽을 ...</td>\n",
       "      <td>지금 너 스스로를 죽여달라고 애원하는 것인가 ? 아닙니다 . 죄송합니다 . 죽을 거...</td>\n",
       "      <td>지금 너 스스로를 죽여달라고 애원하는 것인가 ? 아닙니다 . 죄송합니다 . 죽을 거...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>협박 대화</td>\n",
       "      <td>길동경찰서입니다.\\n9시 40분 마트에 폭발물을 설치할거다.\\n네?\\n똑바로 들어 ...</td>\n",
       "      <td>길동경찰서입니다 . 9시 40분 마트에 폭발물을 설치할거다 . 네 ? 똑바로 들어 ...</td>\n",
       "      <td>길동경찰서입니다 . 9시 40분 마트에 폭발물을 설치할거다 . 네 ? 똑바로 들어 ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>기타 괴롭힘 대화</td>\n",
       "      <td>너 되게 귀여운거 알지? 나보다 작은 남자는 첨봤어.\\n그만해. 니들 놀리는거 재미...</td>\n",
       "      <td>너 되게 귀여운거 알지 ? 나보다 작은 남자는 첨봤어 . 그만해 . 니들 놀리는거 ...</td>\n",
       "      <td>너 되게 귀여운거 알지 ? 나보다 작은 남자는 첨봤어 . 그만해 . 니들 놀리는거 ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>갈취 대화</td>\n",
       "      <td>어이 거기\\n예??\\n너 말이야 너. 이리 오라고\\n무슨 일.\\n너 옷 좋아보인다?...</td>\n",
       "      <td>어이 거기 예 ? ? 너 말이야 너 . 이리 오라고 무슨 일 . 너 옷 좋아보인다 ...</td>\n",
       "      <td>어이 거기 예 ? ? 너 말이야 너 . 이리 오라고 무슨 일 . 너 옷 좋아보인다 ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>갈취 대화</td>\n",
       "      <td>저기요 혹시 날이 너무 뜨겁잖아요? 저희 회사에서 이 선크림 파는데 한 번 손등에 ...</td>\n",
       "      <td>저기요 혹시 날이 너무 뜨겁잖아요 ? 저희 회사에서 이 선크림 파는데 한 번 손등에...</td>\n",
       "      <td>저기요 혹시 날이 너무 뜨겁잖아요 ? 저희 회사에서 선크림 파는데 한 번 손등에 발...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12087</th>\n",
       "      <td>12087</td>\n",
       "      <td>일반</td>\n",
       "      <td>미안하다... 나 내일 회사 하루 쉬려고. 회사를? 어...너무 힘들어서 하루 쉬고...</td>\n",
       "      <td>미안하다 . . . 나 내일 회사 하루 쉬려고 . 회사를 ? 어 . . . 너무 힘...</td>\n",
       "      <td>미안하다 . . . 나 내일 회사 하루 쉬려고 . 회사를 ? 어 . . . 너무 힘...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12088</th>\n",
       "      <td>12088</td>\n",
       "      <td>일반</td>\n",
       "      <td>아~엄마 뭐하는데 이 오밤중에? 난 정말 나간다. 애들처럼 왜 이러냐고? 동네 창피...</td>\n",
       "      <td>아~엄마 뭐하는데 이 오밤중에 ? 난 정말 나간다 . 애들처럼 왜 이러냐고 ? 동네...</td>\n",
       "      <td>아~엄마 뭐하는데 오밤중에 ? 난 정말 나간다 . 애들처럼 왜 이러냐고 ? 동네 창...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12089</th>\n",
       "      <td>12089</td>\n",
       "      <td>일반</td>\n",
       "      <td>니 방에 들어가, 자 임마. 엄마 갑자기 짐 들고 사라질까봐 불안해서 못 나가. 겁...</td>\n",
       "      <td>니 방에 들어가 , 자 임마 . 엄마 갑자기 짐 들고 사라질까봐 불안해서 못 나가 ...</td>\n",
       "      <td>니 방에 들어가 , 자 임마 . 엄마 갑자기 짐 들고 사라질까봐 불안해서 못 나가 ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12090</th>\n",
       "      <td>12090</td>\n",
       "      <td>일반</td>\n",
       "      <td>어, 왜 일어나있어? 힘든데 누워있지. 아니, 이젠 괜찮아 오빠. 뭐가 괜찮아? 어...</td>\n",
       "      <td>어 , 왜 일어나있어 ? 힘든데 누워있지 . 아니 , 이젠 괜찮아 오빠 . 뭐가 괜...</td>\n",
       "      <td>어 , 왜 일어나있어 ? 힘든데 누워있지 . 아니 , 이젠 괜찮아 오빠 . 뭐가 괜...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12091</th>\n",
       "      <td>12091</td>\n",
       "      <td>일반</td>\n",
       "      <td>오랜만에 병원 밖이라도 나가서 점심을 먹으니까 아주 꿀맛이다. 며칠에 한번 집에 들...</td>\n",
       "      <td>오랜만에 병원 밖이라도 나가서 점심을 먹으니까 아주 꿀맛이다 . 며칠에 한번 집에 ...</td>\n",
       "      <td>오랜만에 병원 밖이라도 나가서 점심을 먹으니까 아주 꿀맛이다 . 며칠에 한번 집에 ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>12092 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         idx      class                                       conversation  \\\n",
       "0          0      협박 대화  지금 너 스스로를 죽여달라고 애원하는 것인가?\\n 아닙니다. 죄송합니다.\\n 죽을 ...   \n",
       "1          1      협박 대화  길동경찰서입니다.\\n9시 40분 마트에 폭발물을 설치할거다.\\n네?\\n똑바로 들어 ...   \n",
       "2          2  기타 괴롭힘 대화  너 되게 귀여운거 알지? 나보다 작은 남자는 첨봤어.\\n그만해. 니들 놀리는거 재미...   \n",
       "3          3      갈취 대화  어이 거기\\n예??\\n너 말이야 너. 이리 오라고\\n무슨 일.\\n너 옷 좋아보인다?...   \n",
       "4          4      갈취 대화  저기요 혹시 날이 너무 뜨겁잖아요? 저희 회사에서 이 선크림 파는데 한 번 손등에 ...   \n",
       "...      ...        ...                                                ...   \n",
       "12087  12087         일반  미안하다... 나 내일 회사 하루 쉬려고. 회사를? 어...너무 힘들어서 하루 쉬고...   \n",
       "12088  12088         일반  아~엄마 뭐하는데 이 오밤중에? 난 정말 나간다. 애들처럼 왜 이러냐고? 동네 창피...   \n",
       "12089  12089         일반  니 방에 들어가, 자 임마. 엄마 갑자기 짐 들고 사라질까봐 불안해서 못 나가. 겁...   \n",
       "12090  12090         일반  어, 왜 일어나있어? 힘든데 누워있지. 아니, 이젠 괜찮아 오빠. 뭐가 괜찮아? 어...   \n",
       "12091  12091         일반  오랜만에 병원 밖이라도 나가서 점심을 먹으니까 아주 꿀맛이다. 며칠에 한번 집에 들...   \n",
       "\n",
       "                                  conversation_processed  \\\n",
       "0      지금 너 스스로를 죽여달라고 애원하는 것인가 ? 아닙니다 . 죄송합니다 . 죽을 거...   \n",
       "1      길동경찰서입니다 . 9시 40분 마트에 폭발물을 설치할거다 . 네 ? 똑바로 들어 ...   \n",
       "2      너 되게 귀여운거 알지 ? 나보다 작은 남자는 첨봤어 . 그만해 . 니들 놀리는거 ...   \n",
       "3      어이 거기 예 ? ? 너 말이야 너 . 이리 오라고 무슨 일 . 너 옷 좋아보인다 ...   \n",
       "4      저기요 혹시 날이 너무 뜨겁잖아요 ? 저희 회사에서 이 선크림 파는데 한 번 손등에...   \n",
       "...                                                  ...   \n",
       "12087  미안하다 . . . 나 내일 회사 하루 쉬려고 . 회사를 ? 어 . . . 너무 힘...   \n",
       "12088  아~엄마 뭐하는데 이 오밤중에 ? 난 정말 나간다 . 애들처럼 왜 이러냐고 ? 동네...   \n",
       "12089  니 방에 들어가 , 자 임마 . 엄마 갑자기 짐 들고 사라질까봐 불안해서 못 나가 ...   \n",
       "12090  어 , 왜 일어나있어 ? 힘든데 누워있지 . 아니 , 이젠 괜찮아 오빠 . 뭐가 괜...   \n",
       "12091  오랜만에 병원 밖이라도 나가서 점심을 먹으니까 아주 꿀맛이다 . 며칠에 한번 집에 ...   \n",
       "\n",
       "                                   conversation_filtered  \n",
       "0      지금 너 스스로를 죽여달라고 애원하는 것인가 ? 아닙니다 . 죄송합니다 . 죽을 거...  \n",
       "1      길동경찰서입니다 . 9시 40분 마트에 폭발물을 설치할거다 . 네 ? 똑바로 들어 ...  \n",
       "2      너 되게 귀여운거 알지 ? 나보다 작은 남자는 첨봤어 . 그만해 . 니들 놀리는거 ...  \n",
       "3      어이 거기 예 ? ? 너 말이야 너 . 이리 오라고 무슨 일 . 너 옷 좋아보인다 ...  \n",
       "4      저기요 혹시 날이 너무 뜨겁잖아요 ? 저희 회사에서 선크림 파는데 한 번 손등에 발...  \n",
       "...                                                  ...  \n",
       "12087  미안하다 . . . 나 내일 회사 하루 쉬려고 . 회사를 ? 어 . . . 너무 힘...  \n",
       "12088  아~엄마 뭐하는데 오밤중에 ? 난 정말 나간다 . 애들처럼 왜 이러냐고 ? 동네 창...  \n",
       "12089  니 방에 들어가 , 자 임마 . 엄마 갑자기 짐 들고 사라질까봐 불안해서 못 나가 ...  \n",
       "12090  어 , 왜 일어나있어 ? 힘든데 누워있지 . 아니 , 이젠 괜찮아 오빠 . 뭐가 괜...  \n",
       "12091  오랜만에 병원 밖이라도 나가서 점심을 먹으니까 아주 꿀맛이다 . 며칠에 한번 집에 ...  \n",
       "\n",
       "[12092 rows x 5 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "32bee70e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>idx</th>\n",
       "      <th>class</th>\n",
       "      <th>conversation_filtered</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>협박 대화</td>\n",
       "      <td>지금 너 스스로를 죽여달라고 애원하는 것인가 ? 아닙니다 . 죄송합니다 . 죽을 거...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>협박 대화</td>\n",
       "      <td>길동경찰서입니다 . 9시 40분 마트에 폭발물을 설치할거다 . 네 ? 똑바로 들어 ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>기타 괴롭힘 대화</td>\n",
       "      <td>너 되게 귀여운거 알지 ? 나보다 작은 남자는 첨봤어 . 그만해 . 니들 놀리는거 ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>갈취 대화</td>\n",
       "      <td>어이 거기 예 ? ? 너 말이야 너 . 이리 오라고 무슨 일 . 너 옷 좋아보인다 ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>갈취 대화</td>\n",
       "      <td>저기요 혹시 날이 너무 뜨겁잖아요 ? 저희 회사에서 선크림 파는데 한 번 손등에 발...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12087</th>\n",
       "      <td>12087</td>\n",
       "      <td>일반</td>\n",
       "      <td>미안하다 . . . 나 내일 회사 하루 쉬려고 . 회사를 ? 어 . . . 너무 힘...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12088</th>\n",
       "      <td>12088</td>\n",
       "      <td>일반</td>\n",
       "      <td>아~엄마 뭐하는데 오밤중에 ? 난 정말 나간다 . 애들처럼 왜 이러냐고 ? 동네 창...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12089</th>\n",
       "      <td>12089</td>\n",
       "      <td>일반</td>\n",
       "      <td>니 방에 들어가 , 자 임마 . 엄마 갑자기 짐 들고 사라질까봐 불안해서 못 나가 ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12090</th>\n",
       "      <td>12090</td>\n",
       "      <td>일반</td>\n",
       "      <td>어 , 왜 일어나있어 ? 힘든데 누워있지 . 아니 , 이젠 괜찮아 오빠 . 뭐가 괜...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12091</th>\n",
       "      <td>12091</td>\n",
       "      <td>일반</td>\n",
       "      <td>오랜만에 병원 밖이라도 나가서 점심을 먹으니까 아주 꿀맛이다 . 며칠에 한번 집에 ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>12092 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         idx      class                              conversation_filtered\n",
       "0          0      협박 대화  지금 너 스스로를 죽여달라고 애원하는 것인가 ? 아닙니다 . 죄송합니다 . 죽을 거...\n",
       "1          1      협박 대화  길동경찰서입니다 . 9시 40분 마트에 폭발물을 설치할거다 . 네 ? 똑바로 들어 ...\n",
       "2          2  기타 괴롭힘 대화  너 되게 귀여운거 알지 ? 나보다 작은 남자는 첨봤어 . 그만해 . 니들 놀리는거 ...\n",
       "3          3      갈취 대화  어이 거기 예 ? ? 너 말이야 너 . 이리 오라고 무슨 일 . 너 옷 좋아보인다 ...\n",
       "4          4      갈취 대화  저기요 혹시 날이 너무 뜨겁잖아요 ? 저희 회사에서 선크림 파는데 한 번 손등에 발...\n",
       "...      ...        ...                                                ...\n",
       "12087  12087         일반  미안하다 . . . 나 내일 회사 하루 쉬려고 . 회사를 ? 어 . . . 너무 힘...\n",
       "12088  12088         일반  아~엄마 뭐하는데 오밤중에 ? 난 정말 나간다 . 애들처럼 왜 이러냐고 ? 동네 창...\n",
       "12089  12089         일반  니 방에 들어가 , 자 임마 . 엄마 갑자기 짐 들고 사라질까봐 불안해서 못 나가 ...\n",
       "12090  12090         일반  어 , 왜 일어나있어 ? 힘든데 누워있지 . 아니 , 이젠 괜찮아 오빠 . 뭐가 괜...\n",
       "12091  12091         일반  오랜만에 병원 밖이라도 나가서 점심을 먹으니까 아주 꿀맛이다 . 며칠에 한번 집에 ...\n",
       "\n",
       "[12092 rows x 3 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Q열과 A열 삭제\n",
    "data = data.drop(columns=['conversation', 'conversation_processed'])\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9f2e8849",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>idx</th>\n",
       "      <th>class</th>\n",
       "      <th>conversation</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>협박 대화</td>\n",
       "      <td>지금 너 스스로를 죽여달라고 애원하는 것인가 ? 아닙니다 . 죄송합니다 . 죽을 거...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>협박 대화</td>\n",
       "      <td>길동경찰서입니다 . 9시 40분 마트에 폭발물을 설치할거다 . 네 ? 똑바로 들어 ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>기타 괴롭힘 대화</td>\n",
       "      <td>너 되게 귀여운거 알지 ? 나보다 작은 남자는 첨봤어 . 그만해 . 니들 놀리는거 ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>갈취 대화</td>\n",
       "      <td>어이 거기 예 ? ? 너 말이야 너 . 이리 오라고 무슨 일 . 너 옷 좋아보인다 ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>갈취 대화</td>\n",
       "      <td>저기요 혹시 날이 너무 뜨겁잖아요 ? 저희 회사에서 선크림 파는데 한 번 손등에 발...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12087</th>\n",
       "      <td>12087</td>\n",
       "      <td>일반</td>\n",
       "      <td>미안하다 . . . 나 내일 회사 하루 쉬려고 . 회사를 ? 어 . . . 너무 힘...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12088</th>\n",
       "      <td>12088</td>\n",
       "      <td>일반</td>\n",
       "      <td>아~엄마 뭐하는데 오밤중에 ? 난 정말 나간다 . 애들처럼 왜 이러냐고 ? 동네 창...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12089</th>\n",
       "      <td>12089</td>\n",
       "      <td>일반</td>\n",
       "      <td>니 방에 들어가 , 자 임마 . 엄마 갑자기 짐 들고 사라질까봐 불안해서 못 나가 ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12090</th>\n",
       "      <td>12090</td>\n",
       "      <td>일반</td>\n",
       "      <td>어 , 왜 일어나있어 ? 힘든데 누워있지 . 아니 , 이젠 괜찮아 오빠 . 뭐가 괜...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12091</th>\n",
       "      <td>12091</td>\n",
       "      <td>일반</td>\n",
       "      <td>오랜만에 병원 밖이라도 나가서 점심을 먹으니까 아주 꿀맛이다 . 며칠에 한번 집에 ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>12092 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         idx      class                                       conversation\n",
       "0          0      협박 대화  지금 너 스스로를 죽여달라고 애원하는 것인가 ? 아닙니다 . 죄송합니다 . 죽을 거...\n",
       "1          1      협박 대화  길동경찰서입니다 . 9시 40분 마트에 폭발물을 설치할거다 . 네 ? 똑바로 들어 ...\n",
       "2          2  기타 괴롭힘 대화  너 되게 귀여운거 알지 ? 나보다 작은 남자는 첨봤어 . 그만해 . 니들 놀리는거 ...\n",
       "3          3      갈취 대화  어이 거기 예 ? ? 너 말이야 너 . 이리 오라고 무슨 일 . 너 옷 좋아보인다 ...\n",
       "4          4      갈취 대화  저기요 혹시 날이 너무 뜨겁잖아요 ? 저희 회사에서 선크림 파는데 한 번 손등에 발...\n",
       "...      ...        ...                                                ...\n",
       "12087  12087         일반  미안하다 . . . 나 내일 회사 하루 쉬려고 . 회사를 ? 어 . . . 너무 힘...\n",
       "12088  12088         일반  아~엄마 뭐하는데 오밤중에 ? 난 정말 나간다 . 애들처럼 왜 이러냐고 ? 동네 창...\n",
       "12089  12089         일반  니 방에 들어가 , 자 임마 . 엄마 갑자기 짐 들고 사라질까봐 불안해서 못 나가 ...\n",
       "12090  12090         일반  어 , 왜 일어나있어 ? 힘든데 누워있지 . 아니 , 이젠 괜찮아 오빠 . 뭐가 괜...\n",
       "12091  12091         일반  오랜만에 병원 밖이라도 나가서 점심을 먹으니까 아주 꿀맛이다 . 며칠에 한번 집에 ...\n",
       "\n",
       "[12092 rows x 3 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 열 이름 변경\n",
    "data = data.rename(columns={'conversation_filtered': 'conversation'})\n",
    "data\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c946afc",
   "metadata": {},
   "source": [
    "# Step 3. SubwordTextEncoder 사용하기\n",
    "### 한국어 데이터는 형태소 분석기를 사용하여 토크나이징을 해야 한다고 많은 분이 알고 있습니다. 하지만 여기서는 형태소 분석기가 아닌 위 실습에서 사용했던 내부 단어 토크나이저인 SubwordTextEncoder를 그대로 사용"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94befb17",
   "metadata": {},
   "source": [
    "#### 1. 단어장(Vocabulary) 만들기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9e62540d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16144\n"
     ]
    }
   ],
   "source": [
    "import tensorflow_datasets as tfds\n",
    "\n",
    "# 열 이름 변경\n",
    "data = data.rename(columns={'class': 'class_label'})\n",
    "\n",
    "# 데이터프레임에서 questions와 answers 열을 리스트로 변환\n",
    "conversation = data['conversation'].tolist()\n",
    "class_label = data['class_label'].tolist()\n",
    "\n",
    "# 질문과 답변 데이터셋에 대해서 Vocabulary 생성\n",
    "tokenizer = tfds.deprecated.text.SubwordTextEncoder.build_from_corpus(conversation + class_label, target_vocab_size=2**14)\n",
    "\n",
    "# 시작 토큰과 종료 토큰에 고유한 정수를 부여합니다.\n",
    "START_TOKEN, END_TOKEN = [tokenizer.vocab_size], [tokenizer.vocab_size + 1]\n",
    "\n",
    "# 시작 토큰과 종료 토큰을 고려하여 +2를 하여 단어장의 크기를 산정합니다.\n",
    "VOCAB_SIZE = tokenizer.vocab_size + 2\n",
    "print(VOCAB_SIZE)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ace9f9a9",
   "metadata": {},
   "source": [
    "#### 2. 각 단어를 고유한 정수로 인코딩(Integer encoding) & 패딩(Padding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "13470169",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "정수 인코딩 후의 21번째 질문 샘플: [9, 579, 456, 4801, 150, 64, 12602, 127, 1, 6755, 28, 17, 31, 1560, 1, 25, 18, 12091, 15387, 207, 537, 137, 2674, 1, 7, 17, 6121, 872, 2, 18, 12091, 4923, 2020, 2, 68, 9565, 15918, 64, 8367, 164, 1487, 2443, 3358, 2, 1119, 37, 872, 2, 11394, 11610, 1, 25, 31, 9579, 120, 1, 833, 12091, 5675, 1462, 2, 860, 617, 5]\n",
      "정수 인코딩 후의 21번째 답변 샘플: [87, 13]\n"
     ]
    }
   ],
   "source": [
    "# 각 토큰을 고유한 정수로 변환\n",
    "print('정수 인코딩 후의 21번째 질문 샘플: {}'.format(tokenizer.encode(conversation[21])))\n",
    "print('정수 인코딩 후의 21번째 답변 샘플: {}'.format(tokenizer.encode(class_label[21])))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e628f4d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "대화의 최소 길이 : 8\n",
      "대화의 최대 길이 : 305\n",
      "대화의 평균 길이 : 55.55946080052927\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# 길이 분포 출력\n",
    "conversation_len = [len(s.split()) for s in data['conversation']]\n",
    "class_label_len = [len(s.split()) for s in data['class_label']]\n",
    "\n",
    "print('대화의 최소 길이 : {}'.format(np.min(conversation_len)))\n",
    "print('대화의 최대 길이 : {}'.format(np.max(conversation_len)))\n",
    "print('대화의 평균 길이 : {}'.format(np.mean(conversation_len)))\n",
    "\n",
    "# 길이 분포 시각화\n",
    "plt.subplot(1, 1, 1)\n",
    "plt.boxplot(conversation_len)\n",
    "plt.title('Conversation')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "plt.title('Conversation Length Distribution')\n",
    "plt.hist(conversation_len, bins=40)\n",
    "plt.xlabel('Length of Samples')\n",
    "plt.ylabel('Number of Samples')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a049fb74",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "120\n"
     ]
    }
   ],
   "source": [
    "# 샘플의 최대 허용 길이 또는 패딩 후의 최종 길이\n",
    "MAX_LENGTH = 120\n",
    "print(MAX_LENGTH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "2cd70310",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "단어장의 크기 : 16144\n",
      "필터링 후의 대화 샘플 개수: 11062\n"
     ]
    }
   ],
   "source": [
    "# 정수 인코딩, 최대 길이를 초과하는 샘플 제거, 패딩\n",
    "def tokenize_and_filter(inputs, outputs):\n",
    "  tokenized_inputs, tokenized_outputs = [], []\n",
    "  \n",
    "  for (sentence1, sentence2) in zip(inputs, outputs):\n",
    "    # 정수 인코딩 과정에서 시작 토큰과 종료 토큰을 추가\n",
    "    sentence1 = START_TOKEN + tokenizer.encode(sentence1) + END_TOKEN\n",
    "    sentence2 = START_TOKEN + tokenizer.encode(sentence2) + END_TOKEN\n",
    "\n",
    "    # 최대 길이 140 이하인 경우에만 데이터셋으로 허용\n",
    "    if len(sentence1) <= MAX_LENGTH and len(sentence2) <= MAX_LENGTH:\n",
    "      tokenized_inputs.append(sentence1)\n",
    "      tokenized_outputs.append(sentence2)\n",
    "  \n",
    "  # 최대 길이 140으로 모든 데이터셋을 패딩\n",
    "  tokenized_inputs = tf.keras.preprocessing.sequence.pad_sequences(\n",
    "      tokenized_inputs, maxlen=MAX_LENGTH, padding='post')\n",
    "  tokenized_outputs = tf.keras.preprocessing.sequence.pad_sequences(\n",
    "      tokenized_outputs, maxlen=MAX_LENGTH, padding='post')\n",
    "  \n",
    "  return tokenized_inputs, tokenized_outputs\n",
    "\n",
    "# 정수 인코딩 과정을 수행하면서 샘플의 길이가 140을 넘는 경우는 샘플들을 필터링함. 단어장의 크기와 샘플의 개수를 확인\n",
    "import tensorflow as tf\n",
    "conversation, class_label = tokenize_and_filter(conversation, class_label)\n",
    "print('단어장의 크기 :',(VOCAB_SIZE))\n",
    "print('필터링 후의 대화 샘플 개수: {}'.format(len(conversation)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "0995bfe0",
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 64\n",
    "BUFFER_SIZE = 20000\n",
    "\n",
    "# 디코더는 이전의 target을 다음의 input으로 사용합니다.\n",
    "# 이에 따라 outputs에서는 START_TOKEN을 제거하겠습니다.\n",
    "dataset = tf.data.Dataset.from_tensor_slices((\n",
    "    {\n",
    "        'inputs': conversation,\n",
    "        'dec_inputs': class_label[:, :-1]\n",
    "    },\n",
    "    {\n",
    "        'outputs': class_label[:, 1:]\n",
    "    },\n",
    "))\n",
    "\n",
    "dataset = dataset.cache()\n",
    "dataset = dataset.shuffle(BUFFER_SIZE)\n",
    "dataset = dataset.batch(BATCH_SIZE)\n",
    "dataset = dataset.prefetch(tf.data.experimental.AUTOTUNE)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7523f17",
   "metadata": {},
   "source": [
    "# step 4. 모델 정의"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19f3c8ba",
   "metadata": {},
   "source": [
    "#### 9-4. 트랜스포머의 입력 이해하기_포지셔널 인코딩 레이어"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "d933de61",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "슝=3\n"
     ]
    }
   ],
   "source": [
    "# 포지셔널 인코딩 레이어\n",
    "class PositionalEncoding(tf.keras.layers.Layer):\n",
    "\n",
    "  def __init__(self, position, d_model):\n",
    "    super(PositionalEncoding, self).__init__()\n",
    "    self.pos_encoding = self.positional_encoding(position, d_model)\n",
    "\n",
    "  def get_angles(self, position, i, d_model):\n",
    "    angles = 1 / tf.pow(10000, (2 * (i // 2)) / tf.cast(d_model, tf.float32))\n",
    "    return position * angles\n",
    "\n",
    "  def positional_encoding(self, position, d_model):\n",
    "    # 각도 배열 생성\n",
    "    angle_rads = self.get_angles(\n",
    "        position=tf.range(position, dtype=tf.float32)[:, tf.newaxis],\n",
    "        i=tf.range(d_model, dtype=tf.float32)[tf.newaxis, :],\n",
    "        d_model=d_model)\n",
    "\n",
    "    # 배열의 짝수 인덱스에는 sin 함수 적용\n",
    "    sines = tf.math.sin(angle_rads[:, 0::2])\n",
    "    # 배열의 홀수 인덱스에는 cosine 함수 적용\n",
    "    cosines = tf.math.cos(angle_rads[:, 1::2])\n",
    "\n",
    "    # sin과 cosine이 교차되도록 재배열\n",
    "    pos_encoding = tf.stack([sines, cosines], axis=0)\n",
    "    pos_encoding = tf.transpose(pos_encoding,[1, 2, 0]) \n",
    "    pos_encoding = tf.reshape(pos_encoding, [position, d_model])\n",
    "\n",
    "    pos_encoding = pos_encoding[tf.newaxis, ...]\n",
    "    return tf.cast(pos_encoding, tf.float32)\n",
    "\n",
    "  def call(self, inputs):\n",
    "    return inputs + self.pos_encoding[:, :tf.shape(inputs)[1], :]\n",
    "\n",
    "print(\"슝=3\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0acbcc9a",
   "metadata": {},
   "source": [
    "#### 9-6. 스케일드 닷 프로덕트 어텐션"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "c235dc92",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "슝=3\n"
     ]
    }
   ],
   "source": [
    "# 스케일드 닷 프로덕트 어텐션 함수\n",
    "def scaled_dot_product_attention(query, key, value, mask):\n",
    "  # 어텐션 가중치는 Q와 K의 닷 프로덕트\n",
    "  matmul_qk = tf.matmul(query, key, transpose_b=True)\n",
    "\n",
    "  # 가중치를 정규화\n",
    "  depth = tf.cast(tf.shape(key)[-1], tf.float32)\n",
    "  logits = matmul_qk / tf.math.sqrt(depth)\n",
    "\n",
    "  # 패딩에 마스크 추가\n",
    "  if mask is not None:\n",
    "    logits += (mask * -1e9)\n",
    "\n",
    "  # softmax적용\n",
    "  attention_weights = tf.nn.softmax(logits, axis=-1)\n",
    "\n",
    "  # 최종 어텐션은 가중치와 V의 닷 프로덕트\n",
    "  output = tf.matmul(attention_weights, value)\n",
    "  return output\n",
    "\n",
    "print(\"슝=3\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ad92816",
   "metadata": {},
   "source": [
    "#### 9-7. 머리가 여러 개인 어텐션_멀티 헤드 어텐션 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "8cabc561",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "슝=3\n"
     ]
    }
   ],
   "source": [
    "class MultiHeadAttention(tf.keras.layers.Layer):\n",
    "\n",
    "  def __init__(self, d_model, num_heads, name=\"multi_head_attention\"):\n",
    "    super(MultiHeadAttention, self).__init__(name=name)\n",
    "    self.num_heads = num_heads\n",
    "    self.d_model = d_model\n",
    "\n",
    "    assert d_model % self.num_heads == 0\n",
    "\n",
    "    self.depth = d_model // self.num_heads\n",
    "\n",
    "    self.query_dense = tf.keras.layers.Dense(units=d_model)\n",
    "    self.key_dense = tf.keras.layers.Dense(units=d_model)\n",
    "    self.value_dense = tf.keras.layers.Dense(units=d_model)\n",
    "\n",
    "    self.dense = tf.keras.layers.Dense(units=d_model)\n",
    "\n",
    "  def split_heads(self, inputs, batch_size):\n",
    "    inputs = tf.reshape(\n",
    "        inputs, shape=(batch_size, -1, self.num_heads, self.depth))\n",
    "    return tf.transpose(inputs, perm=[0, 2, 1, 3])\n",
    "\n",
    "  def call(self, inputs):\n",
    "    query, key, value, mask = inputs['query'], inputs['key'], inputs[\n",
    "        'value'], inputs['mask']\n",
    "    batch_size = tf.shape(query)[0]\n",
    "\n",
    "    # Q, K, V에 각각 Dense를 적용합니다\n",
    "    query = self.query_dense(query)  # Dense를 적용\n",
    "    key = self.key_dense(key)        # Dense를 적용\n",
    "    value = self.value_dense(value)  # Dense를 적용\n",
    "    # 병렬 연산을 위한 머리를 여러 개 만듭니다\n",
    "    query = self.split_heads(query, batch_size)  # 머리 분리\n",
    "    key = self.split_heads(key, batch_size)        # 머리 분리\n",
    "    value = self.split_heads(value, batch_size)\n",
    "\n",
    "    # 스케일드 닷 프로덕트 어텐션 함수\n",
    "    scaled_attention = scaled_dot_product_attention(query, key, value, mask)\n",
    "\n",
    "    scaled_attention = tf.transpose(scaled_attention, perm=[0, 2, 1, 3])\n",
    "\n",
    "    # 어텐션 연산 후에 각 결과를 다시 연결(concatenate)합니다\n",
    "    concat_attention = tf.reshape(scaled_attention,\n",
    "                                  (batch_size, -1, self.d_model))\n",
    "\n",
    "    # 최종 결과에도 Dense를 한 번 더 적용합니다\n",
    "    outputs = self.dense(concat_attention)\n",
    "\n",
    "    return outputs\n",
    "print(\"슝=3\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9bfab25a",
   "metadata": {},
   "source": [
    "#### 9-8. 마스킹"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "8c4145bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "슝=3\n"
     ]
    }
   ],
   "source": [
    "def create_padding_mask(x):\n",
    "  mask = tf.cast(tf.math.equal(x, 0), tf.float32)\n",
    "  # (batch_size, 1, 1, sequence length)\n",
    "  return mask[:, tf.newaxis, tf.newaxis, :]\n",
    "print(\"슝=3\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "2f103c1d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "슝=3\n"
     ]
    }
   ],
   "source": [
    "def create_look_ahead_mask(x):\n",
    "  seq_len = tf.shape(x)[1]\n",
    "  look_ahead_mask = 1 - tf.linalg.band_part(tf.ones((seq_len, seq_len)), -1, 0)\n",
    "  padding_mask = create_padding_mask(x)\n",
    "  return tf.maximum(look_ahead_mask, padding_mask)\n",
    "print(\"슝=3\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0249f408",
   "metadata": {},
   "source": [
    "#### 9-9. 인코더"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "cba67329",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 인코더 하나의 레이어를 함수로 구현.\n",
    "# 이 하나의 레이어 안에는 두 개의 서브 레이어가 존재합니다.\n",
    "def encoder_layer(units, d_model, num_heads, dropout, name=\"encoder_layer\"):\n",
    "  inputs = tf.keras.Input(shape=(None, d_model), name=\"inputs\")\n",
    "\n",
    "  # 패딩 마스크 사용\n",
    "  padding_mask = tf.keras.Input(shape=(1, 1, None), name=\"padding_mask\")\n",
    "\n",
    "  # 첫 번째 서브 레이어 : 멀티 헤드 어텐션 수행 (셀프 어텐션)\n",
    "  attention = MultiHeadAttention(\n",
    "      d_model, num_heads, name=\"attention\")({\n",
    "          'query': inputs,\n",
    "          'key': inputs,\n",
    "          'value': inputs,\n",
    "          'mask': padding_mask\n",
    "      })\n",
    "\n",
    "  # 어텐션의 결과는 Dropout과 Layer Normalization이라는 훈련을 돕는 테크닉을 수행\n",
    "  attention = tf.keras.layers.Dropout(rate=dropout)(attention)\n",
    "  attention = tf.keras.layers.LayerNormalization(\n",
    "      epsilon=1e-6)(inputs + attention)\n",
    "\n",
    "  # 두 번째 서브 레이어 : 2개의 완전연결층\n",
    "  outputs = tf.keras.layers.Dense(units=units, activation='relu')(attention)\n",
    "  outputs = tf.keras.layers.Dense(units=d_model)(outputs)\n",
    "\n",
    "  # 완전연결층의 결과는 Dropout과 LayerNormalization이라는 훈련을 돕는 테크닉을 수행\n",
    "  outputs = tf.keras.layers.Dropout(rate=dropout)(outputs)\n",
    "  outputs = tf.keras.layers.LayerNormalization(\n",
    "      epsilon=1e-6)(attention + outputs)\n",
    "\n",
    "  return tf.keras.Model(\n",
    "      inputs=[inputs, padding_mask], outputs=outputs, name=name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "e5ad291c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def encoder(vocab_size,\n",
    "            num_layers,\n",
    "            units,\n",
    "            d_model,\n",
    "            num_heads,\n",
    "            dropout,\n",
    "            name=\"encoder\"):\n",
    "  inputs = tf.keras.Input(shape=(None,), name=\"inputs\")\n",
    "\n",
    "  # 패딩 마스크 사용\n",
    "  padding_mask = tf.keras.Input(shape=(1, 1, None), name=\"padding_mask\")\n",
    "\n",
    "  # 임베딩 레이어\n",
    "  embeddings = tf.keras.layers.Embedding(vocab_size, d_model)(inputs)\n",
    "  embeddings *= tf.math.sqrt(tf.cast(d_model, tf.float32))\n",
    "\n",
    "  # 포지셔널 인코딩\n",
    "  embeddings = PositionalEncoding(vocab_size, d_model)(embeddings)\n",
    "\n",
    "  outputs = tf.keras.layers.Dropout(rate=dropout)(embeddings)\n",
    "\n",
    "  # num_layers만큼 쌓아올린 인코더의 층.\n",
    "  for i in range(num_layers):\n",
    "    outputs = encoder_layer(\n",
    "        units=units,\n",
    "        d_model=d_model,\n",
    "        num_heads=num_heads,\n",
    "        dropout=dropout,\n",
    "        name=\"encoder_layer_{}\".format(i),\n",
    "    )([outputs, padding_mask])\n",
    "\n",
    "  return tf.keras.Model(\n",
    "      inputs=[inputs, padding_mask], outputs=outputs, name=name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa9c46c0",
   "metadata": {},
   "source": [
    "#### 9-10. 디코더"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "ad2f5b6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 디코더 하나의 레이어를 함수로 구현.\n",
    "# 이 하나의 레이어 안에는 세 개의 서브 레이어가 존재합니다.\n",
    "def decoder_layer(units, d_model, num_heads, dropout, name=\"decoder_layer\"):\n",
    "  inputs = tf.keras.Input(shape=(None, d_model), name=\"inputs\")\n",
    "  enc_outputs = tf.keras.Input(shape=(None, d_model), name=\"encoder_outputs\")\n",
    "  look_ahead_mask = tf.keras.Input(\n",
    "      shape=(1, None, None), name=\"look_ahead_mask\")\n",
    "  padding_mask = tf.keras.Input(shape=(1, 1, None), name='padding_mask')\n",
    "\n",
    "  # 첫 번째 서브 레이어 : 멀티 헤드 어텐션 수행 (셀프 어텐션)\n",
    "  attention1 = MultiHeadAttention(\n",
    "      d_model, num_heads, name=\"attention_1\")(inputs={\n",
    "          'query': inputs,\n",
    "          'key': inputs,\n",
    "          'value': inputs,\n",
    "          'mask': look_ahead_mask\n",
    "      })\n",
    "\n",
    "  # 멀티 헤드 어텐션의 결과는 LayerNormalization이라는 훈련을 돕는 테크닉을 수행\n",
    "  attention1 = tf.keras.layers.LayerNormalization(\n",
    "      epsilon=1e-6)(attention1 + inputs)\n",
    "\n",
    "  # 두 번째 서브 레이어 : 마스크드 멀티 헤드 어텐션 수행 (인코더-디코더 어텐션)\n",
    "  attention2 = MultiHeadAttention(\n",
    "      d_model, num_heads, name=\"attention_2\")(inputs={\n",
    "          'query': attention1,\n",
    "          'key': enc_outputs,\n",
    "          'value': enc_outputs,\n",
    "          'mask': padding_mask\n",
    "      })\n",
    "\n",
    "  # 마스크드 멀티 헤드 어텐션의 결과는\n",
    "  # Dropout과 LayerNormalization이라는 훈련을 돕는 테크닉을 수행\n",
    "  attention2 = tf.keras.layers.Dropout(rate=dropout)(attention2)\n",
    "  attention2 = tf.keras.layers.LayerNormalization(\n",
    "      epsilon=1e-6)(attention2 + attention1)\n",
    "\n",
    "  # 세 번째 서브 레이어 : 2개의 완전연결층\n",
    "  outputs = tf.keras.layers.Dense(units=units, activation='relu')(attention2)\n",
    "  outputs = tf.keras.layers.Dense(units=d_model)(outputs)\n",
    "\n",
    "  # 완전연결층의 결과는 Dropout과 LayerNormalization 수행\n",
    "  outputs = tf.keras.layers.Dropout(rate=dropout)(outputs)\n",
    "  outputs = tf.keras.layers.LayerNormalization(\n",
    "      epsilon=1e-6)(outputs + attention2)\n",
    "\n",
    "  return tf.keras.Model(\n",
    "      inputs=[inputs, enc_outputs, look_ahead_mask, padding_mask],\n",
    "      outputs=outputs,\n",
    "      name=name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "14403472",
   "metadata": {},
   "outputs": [],
   "source": [
    "def decoder(vocab_size,\n",
    "            num_layers,\n",
    "            units,\n",
    "            d_model,\n",
    "            num_heads,\n",
    "            dropout,\n",
    "            name='decoder'):\n",
    "  inputs = tf.keras.Input(shape=(None,), name='inputs')\n",
    "  enc_outputs = tf.keras.Input(shape=(None, d_model), name='encoder_outputs')\n",
    "  look_ahead_mask = tf.keras.Input(\n",
    "      shape=(1, None, None), name='look_ahead_mask')\n",
    "\n",
    "  # 패딩 마스크\n",
    "  padding_mask = tf.keras.Input(shape=(1, 1, None), name='padding_mask')\n",
    "  \n",
    "  # 임베딩 레이어\n",
    "  embeddings = tf.keras.layers.Embedding(vocab_size, d_model)(inputs)\n",
    "  embeddings *= tf.math.sqrt(tf.cast(d_model, tf.float32))\n",
    "\n",
    "  # 포지셔널 인코딩\n",
    "  embeddings = PositionalEncoding(vocab_size, d_model)(embeddings)\n",
    "\n",
    "  # Dropout이라는 훈련을 돕는 테크닉을 수행\n",
    "  outputs = tf.keras.layers.Dropout(rate=dropout)(embeddings)\n",
    "\n",
    "  for i in range(num_layers):\n",
    "    outputs = decoder_layer(\n",
    "        units=units,\n",
    "        d_model=d_model,\n",
    "        num_heads=num_heads,\n",
    "        dropout=dropout,\n",
    "        name='decoder_layer_{}'.format(i),\n",
    "    )(inputs=[outputs, enc_outputs, look_ahead_mask, padding_mask])\n",
    "\n",
    "  return tf.keras.Model(\n",
    "      inputs=[inputs, enc_outputs, look_ahead_mask, padding_mask],\n",
    "      outputs=outputs,\n",
    "      name=name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d473d77",
   "metadata": {},
   "source": [
    "# step 5. 트랜스포머 구현"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "909db8be",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "슝=3\n"
     ]
    }
   ],
   "source": [
    "target_vocab_size = 2**14\n",
    "\n",
    "def transformer(vocab_size,\n",
    "                num_layers,\n",
    "                units,\n",
    "                d_model,\n",
    "                num_heads,\n",
    "                dropout,\n",
    "                name=\"transformer\"):\n",
    "  inputs = tf.keras.Input(shape=(None,), name=\"inputs\")\n",
    "  dec_inputs = tf.keras.Input(shape=(None,), name=\"dec_inputs\")\n",
    "\n",
    "  # 인코더에서 패딩을 위한 마스크\n",
    "  enc_padding_mask = tf.keras.layers.Lambda(\n",
    "      create_padding_mask, output_shape=(1, 1, None),\n",
    "      name='enc_padding_mask')(inputs)\n",
    "\n",
    "  # 디코더에서 미래의 토큰을 마스크 하기 위해서 사용합니다.\n",
    "  # 내부적으로 패딩 마스크도 포함되어져 있습니다.\n",
    "  look_ahead_mask = tf.keras.layers.Lambda(\n",
    "      create_look_ahead_mask,\n",
    "      output_shape=(1, None, None),\n",
    "      name='look_ahead_mask')(dec_inputs)\n",
    "\n",
    "  # 두 번째 어텐션 블록에서 인코더의 벡터들을 마스킹\n",
    "  # 디코더에서 패딩을 위한 마스크\n",
    "  dec_padding_mask = tf.keras.layers.Lambda(\n",
    "      create_padding_mask, output_shape=(1, 1, None),\n",
    "      name='dec_padding_mask')(inputs)\n",
    "\n",
    "  # 인코더\n",
    "  enc_outputs = encoder(\n",
    "      vocab_size=vocab_size,\n",
    "      num_layers=num_layers,\n",
    "      units=units,\n",
    "      d_model=d_model,\n",
    "      num_heads=num_heads,\n",
    "      dropout=dropout,\n",
    "  )(inputs=[inputs, enc_padding_mask])\n",
    "\n",
    "  # 디코더\n",
    "  dec_outputs = decoder(\n",
    "      vocab_size=target_vocab_size,\n",
    "      num_layers=num_layers,\n",
    "      units=units,\n",
    "      d_model=d_model,\n",
    "      num_heads=num_heads,\n",
    "      dropout=dropout,\n",
    "  )(inputs=[dec_inputs, enc_outputs, look_ahead_mask, dec_padding_mask])\n",
    "\n",
    "  # 완전연결층\n",
    "  outputs = tf.keras.layers.Dense(units=vocab_size, name=\"outputs\")(dec_outputs)\n",
    "\n",
    "  return tf.keras.Model(inputs=[inputs, dec_inputs], outputs=outputs, name=name)\n",
    "print(\"슝=3\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79ce33e9",
   "metadata": {},
   "source": [
    "# step 6. 모델 학습"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "2d06884a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 모델 정의"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "5c54fbcc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"transformer\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "inputs (InputLayer)             [(None, None)]       0                                            \n",
      "__________________________________________________________________________________________________\n",
      "dec_inputs (InputLayer)         [(None, None)]       0                                            \n",
      "__________________________________________________________________________________________________\n",
      "enc_padding_mask (Lambda)       (None, 1, 1, None)   0           inputs[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "encoder (Functional)            (None, None, 256)    5187072     inputs[0][0]                     \n",
      "                                                                 enc_padding_mask[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "look_ahead_mask (Lambda)        (None, 1, None, None 0           dec_inputs[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dec_padding_mask (Lambda)       (None, 1, 1, None)   0           inputs[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "decoder (Functional)            (None, None, 256)    5775872     dec_inputs[0][0]                 \n",
      "                                                                 encoder[0][0]                    \n",
      "                                                                 look_ahead_mask[0][0]            \n",
      "                                                                 dec_padding_mask[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "outputs (Dense)                 (None, None, 16144)  4149008     decoder[0][0]                    \n",
      "==================================================================================================\n",
      "Total params: 15,111,952\n",
      "Trainable params: 15,111,952\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "tf.keras.backend.clear_session()\n",
    "\n",
    "# 하이퍼파라미터\n",
    "NUM_LAYERS = 2 # 인코더와 디코더의 층의 개수\n",
    "D_MODEL = 256 # 인코더와 디코더 내부의 입, 출력의 고정 차원\n",
    "NUM_HEADS = 8 # 멀티 헤드 어텐션에서의 헤드 수 \n",
    "UNITS = 512 # 피드 포워드 신경망의 은닉층의 크기\n",
    "DROPOUT = 0.05 # 드롭아웃의 비율\n",
    "\n",
    "model = transformer(\n",
    "    vocab_size=VOCAB_SIZE,\n",
    "    num_layers=NUM_LAYERS,\n",
    "    units=UNITS,\n",
    "    d_model=D_MODEL,\n",
    "    num_heads=NUM_HEADS,\n",
    "    dropout=DROPOUT)\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "5786b46f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 손실함수 정의"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "c8c29d11",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "슝=3\n"
     ]
    }
   ],
   "source": [
    "def loss_function(y_true, y_pred):\n",
    "  y_true = tf.reshape(y_true, shape=(-1, MAX_LENGTH - 1))\n",
    "  \n",
    "  loss = tf.keras.losses.SparseCategoricalCrossentropy(\n",
    "      from_logits=True, reduction='none')(y_true, y_pred)\n",
    "\n",
    "  mask = tf.cast(tf.not_equal(y_true, 0), tf.float32)\n",
    "  loss = tf.multiply(loss, mask)\n",
    "\n",
    "  return tf.reduce_mean(loss)\n",
    "print(\"슝=3\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "b06a398d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 커스텀 된 학습률"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "e63942ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "슝=3\n"
     ]
    }
   ],
   "source": [
    "class CustomSchedule(tf.keras.optimizers.schedules.LearningRateSchedule):\n",
    "\n",
    "  def __init__(self, d_model, warmup_steps=4000):\n",
    "    super(CustomSchedule, self).__init__()\n",
    "\n",
    "    self.d_model = d_model\n",
    "    self.d_model = tf.cast(self.d_model, tf.float32)\n",
    "\n",
    "    self.warmup_steps = warmup_steps\n",
    "\n",
    "  def __call__(self, step):\n",
    "    arg1 = tf.math.rsqrt(step)\n",
    "    arg2 = step * (self.warmup_steps**-1.5)\n",
    "\n",
    "    return tf.math.rsqrt(self.d_model) * tf.math.minimum(arg1, arg2)\n",
    "print(\"슝=3\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "b6b5c6f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 모델 컴파일"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "c3b7b275",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "슝=3\n"
     ]
    }
   ],
   "source": [
    "learning_rate = CustomSchedule(D_MODEL)\n",
    "\n",
    "optimizer = tf.keras.optimizers.Adam(\n",
    "    learning_rate, beta_1=0.9, beta_2=0.98, epsilon=1e-9)\n",
    "\n",
    "def accuracy(y_true, y_pred):\n",
    "  y_true = tf.reshape(y_true, shape=(-1, MAX_LENGTH - 1))\n",
    "  return tf.keras.metrics.sparse_categorical_accuracy(y_true, y_pred)\n",
    "\n",
    "model.compile(optimizer=optimizer, loss=loss_function, metrics=[accuracy])\n",
    "print(\"슝=3\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "2e1c42dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 훈련"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "be706a34",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/9\n",
      "173/173 [==============================] - 37s 180ms/step - loss: 0.1746 - accuracy: 0.0087\n",
      "Epoch 2/9\n",
      "173/173 [==============================] - 32s 184ms/step - loss: 0.0884 - accuracy: 0.0175\n",
      "Epoch 3/9\n",
      "173/173 [==============================] - 33s 189ms/step - loss: 0.0149 - accuracy: 0.0191\n",
      "Epoch 4/9\n",
      "173/173 [==============================] - 33s 191ms/step - loss: 0.0038 - accuracy: 0.0202\n",
      "Epoch 5/9\n",
      "173/173 [==============================] - 33s 189ms/step - loss: 0.0012 - accuracy: 0.0209\n",
      "Epoch 6/9\n",
      "173/173 [==============================] - 33s 190ms/step - loss: 4.1086e-04 - accuracy: 0.0211\n",
      "Epoch 7/9\n",
      "173/173 [==============================] - 33s 190ms/step - loss: 2.9204e-04 - accuracy: 0.0211\n",
      "Epoch 8/9\n",
      "173/173 [==============================] - 33s 190ms/step - loss: 2.4561e-04 - accuracy: 0.0211\n",
      "Epoch 9/9\n",
      "173/173 [==============================] - 33s 190ms/step - loss: 1.5004e-04 - accuracy: 0.0212\n"
     ]
    }
   ],
   "source": [
    "EPOCHS = 9\n",
    "history = model.fit(dataset, epochs=EPOCHS, verbose=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "c0fb0465",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 864x432 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 손실 값 그래프\n",
    "plt.figure(figsize=(12, 6))\n",
    "\n",
    "# Loss 그래프\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(history.history['loss'], label='Training Loss', marker='o')\n",
    "plt.title('Training Loss')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.grid(True)\n",
    "plt.legend()\n",
    "\n",
    "# 정확도 그래프\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(history.history['accuracy'], label='Training Accuracy', marker='o')\n",
    "plt.title('Training Accuracy')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.grid(True)\n",
    "plt.legend()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "a7d5e22d",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>idx</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>t_000</td>\n",
       "      <td>아가씨 담배한갑주소 네 4500원입니다 어 네 지갑어디갔지 에이 버스에서 잃어버렸나...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>t_001</td>\n",
       "      <td>우리팀에서 다른팀으로 갈 사람 없나? 그럼 영지씨가 가는건 어때?  네? 제가요? ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>t_002</td>\n",
       "      <td>너 오늘 그게 뭐야 네 제가 뭘 잘못했나요.? 제대로 좀 하지 네 똑바로 좀 하지 ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>t_003</td>\n",
       "      <td>이거 들어바 와 이 노래 진짜 좋다 그치 요즘 이 것만 들어 진짜 너무 좋다 내가 ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>t_004</td>\n",
       "      <td>아무튼 앞으로 니가 내 와이파이야. .응 와이파이 온. 켰어. 반말? 주인님이라고도...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     idx                                               text\n",
       "0  t_000  아가씨 담배한갑주소 네 4500원입니다 어 네 지갑어디갔지 에이 버스에서 잃어버렸나...\n",
       "1  t_001  우리팀에서 다른팀으로 갈 사람 없나? 그럼 영지씨가 가는건 어때?  네? 제가요? ...\n",
       "2  t_002  너 오늘 그게 뭐야 네 제가 뭘 잘못했나요.? 제대로 좀 하지 네 똑바로 좀 하지 ...\n",
       "3  t_003  이거 들어바 와 이 노래 진짜 좋다 그치 요즘 이 것만 들어 진짜 너무 좋다 내가 ...\n",
       "4  t_004  아무튼 앞으로 니가 내 와이파이야. .응 와이파이 온. 켰어. 반말? 주인님이라고도..."
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data_path =\"aiffel/dktc/test.csv\"\n",
    "test_data = pd.read_csv(test_data_path)\n",
    "test_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "e977948d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(sentence):\n",
    "  sentence = preprocess_sentence(sentence)\n",
    "\n",
    "  sentence = tf.expand_dims(\n",
    "      START_TOKEN + tokenizer.encode(sentence) + END_TOKEN, axis=0)\n",
    "\n",
    "  output = tf.expand_dims(START_TOKEN, 0)\n",
    "\n",
    "  # 디코더의 예측 시작\n",
    "  for i in range(MAX_LENGTH):\n",
    "    predictions = model(inputs=[sentence, output], training=False)\n",
    "\n",
    "    # 현재(마지막) 시점의 예측 단어를 받아온다.\n",
    "    predictions = predictions[:, -1:, :]\n",
    "    predicted_id = tf.cast(tf.argmax(predictions, axis=-1), tf.int32)\n",
    "\n",
    "    # 만약 마지막 시점의 예측 단어가 종료 토큰이라면 예측을 중단\n",
    "    if tf.equal(predicted_id, END_TOKEN[0]):\n",
    "      break\n",
    "\n",
    "    # 마지막 시점의 예측 단어를 출력에 연결한다.\n",
    "    # 이는 for문을 통해서 디코더의 입력으로 사용될 예정이다.\n",
    "    output = tf.concat([output, predicted_id], axis=-1)\n",
    "\n",
    "  return tf.squeeze(output, axis=0)\n",
    "\n",
    "\n",
    "def predict(sentence):\n",
    "  prediction = evaluate(sentence)\n",
    "\n",
    "  predicted_sentence = tokenizer.decode(\n",
    "      [i for i in prediction if i < tokenizer.vocab_size])\n",
    "\n",
    "  print('Input: {}'.format(sentence))\n",
    "  print('Output: {}'.format(predicted_sentence))\n",
    "\n",
    "  return predicted_sentence\n",
    "def preprocess_sentence(sentence):\n",
    "  sentence = re.sub(r\"([?.!,])\", r\" \\1 \", sentence)\n",
    "  sentence = sentence.strip()\n",
    "  return sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "9b4c2eb1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input: 아가씨 담배한갑주소 네 4500원입니다 어 네 지갑어디갔지 에이 버스에서 잃어버렸나보네 그럼 취소할까요 아가씨 내 여기단골이니 담에 갖다줄께 저도 알바생이라 외상안됩니다 아따 누가 떼먹는다고 그러나 갖다준다고 안됩니다 자꾸이럼 경찰불러요 아가씨 담배피는교 그건 왜 물으세요 그람 아가씨 담배 한대만 빌립시다 내 지금 지갑도 잃어버리고 기분이 그래서 그러니 여기요  아따 주는김에 한개더 주면 되겠네\n",
      "Output: 갈취 대화\n"
     ]
    }
   ],
   "source": [
    "output = predict('아가씨 담배한갑주소 네 4500원입니다 어 네 지갑어디갔지 에이 버스에서 잃어버렸나보네 그럼 취소할까요 아가씨 내 여기단골이니 담에 갖다줄께 저도 알바생이라 외상안됩니다 아따 누가 떼먹는다고 그러나 갖다준다고 안됩니다 자꾸이럼 경찰불러요 아가씨 담배피는교 그건 왜 물으세요 그람 아가씨 담배 한대만 빌립시다 내 지금 지갑도 잃어버리고 기분이 그래서 그러니 여기요  아따 주는김에 한개더 주면 되겠네')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "a3f86b2d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input: 우리팀에서 다른팀으로 갈 사람 없나? 그럼 영지씨가 가는건 어때?  네? 제가요? 그렇지? 2달만 파견 잘 갔다오면 승진이야. 네? 저는 별로 가고 싶지 않습니다. 여기 있는 모든사람도 가기 싫어해. 그러니까 막내인 영지씨가 가는게 맞지 정말 죄송합니다. 저는 못갑니다. 장난해? 모두를 위해 영지씨가 희생하는게 싫어? 네. 부당한 방법으로 가는 것 같습니다. 영지씨 안가면 회사생활 오래 못할 것 같은데 그래도 안갈거야? 안가면 지옥일텐데. 그래도 이 방법은 아닌 것 같습니다. 죄송합니다.\n",
      "Output: 직장 내 괴롭힘 대화\n"
     ]
    }
   ],
   "source": [
    "output = predict('우리팀에서 다른팀으로 갈 사람 없나? 그럼 영지씨가 가는건 어때?  네? 제가요? 그렇지? 2달만 파견 잘 갔다오면 승진이야. 네? 저는 별로 가고 싶지 않습니다. 여기 있는 모든사람도 가기 싫어해. 그러니까 막내인 영지씨가 가는게 맞지 정말 죄송합니다. 저는 못갑니다. 장난해? 모두를 위해 영지씨가 희생하는게 싫어? 네. 부당한 방법으로 가는 것 같습니다. 영지씨 안가면 회사생활 오래 못할 것 같은데 그래도 안갈거야? 안가면 지옥일텐데. 그래도 이 방법은 아닌 것 같습니다. 죄송합니다.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "7b2b3ac6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input: 너 오늘 그게 뭐야 네 제가 뭘 잘못했나요.? 제대로 좀 하지 네 똑바로 좀 하지 행실이 맘에 안들어 네 실천할께요 옆에 동기들 좀 본받으란 말야 어? 네 알겠습니다 그래 똑바로해 노럭할께요\n",
      "Output: 직장 내 괴롭힘 대화\n"
     ]
    }
   ],
   "source": [
    "output = predict('너 오늘 그게 뭐야 네 제가 뭘 잘못했나요.? 제대로 좀 하지 네 똑바로 좀 하지 행실이 맘에 안들어 네 실천할께요 옆에 동기들 좀 본받으란 말야 어? 네 알겠습니다 그래 똑바로해 노럭할께요')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "462966ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input: 그러니까 빨리 말해. 선생님 제발 살려주십시오.  비밀번호 틀릴 때마다 손톱 하나씩 뺀찌로 뽑는다.  선생님 저도 정말 모릅니다.  하나 엄지 손톱 뽑는다.  으악! 잘못했습니다. 그런데 진짜 모릅니다.  둘 이번에는 두 번째 손톱 뽑는다.  으악! 진짜 저는 모릅니다.  셋 중지를 아주 분질러 줄까?  으아아 살려주십시오.  아니다 아주 손가락을 다 잘라놔야겠다.\n",
      "Output: 협박 대화\n"
     ]
    }
   ],
   "source": [
    "output = predict('그러니까 빨리 말해. 선생님 제발 살려주십시오.  비밀번호 틀릴 때마다 손톱 하나씩 뺀찌로 뽑는다.  선생님 저도 정말 모릅니다.  하나 엄지 손톱 뽑는다.  으악! 잘못했습니다. 그런데 진짜 모릅니다.  둘 이번에는 두 번째 손톱 뽑는다.  으악! 진짜 저는 모릅니다.  셋 중지를 아주 분질러 줄까?  으아아 살려주십시오.  아니다 아주 손가락을 다 잘라놔야겠다.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "35a3b584",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input: 야 너 2학년 김민석 맞지? 네 맞는데요. 혹시 누구신가요? 내가 누군지 궁금하면 학교 뒤쪽으로 내려와. 2분 준다. 네 지금 내려가겠습니다. 야 니가 김민석이냐? 돈 있어? 돈 없는데요. 야 쟤 몸뒤져. 너 천 원 나올 때마다 얼차려 10분이다. 야 여기 얘 지갑 있는데? 오 지갑만 봐도 돈 많게 생겼네. 열어봐봐 오 12만원 있네? 얼차려가 몇 분이야? 야 이 돈 주면 얼차려 없애줄게. 그거 오늘 저 문제집 사려고 가져온 돈이라. 혹시 내일 드리면 안될까요? 야 니 얼차려 받고 싶냐? 그렇게 내일 주고 싶으면 오늘 이 돈도 우리 주고 내일도 돈 가져다 주면 돼. 뭐가 어려워. 네 알겠습니다. 그 12만원 가져게세요. 말 잘 듣네. 아주 예뻐 내일도 돈 가져와라. 안 그러면 알지? 내일도 같은 시간에 여기로 와.\n",
      "Output: 갈취 대화\n"
     ]
    }
   ],
   "source": [
    "output = predict('야 너 2학년 김민석 맞지? 네 맞는데요. 혹시 누구신가요? 내가 누군지 궁금하면 학교 뒤쪽으로 내려와. 2분 준다. 네 지금 내려가겠습니다. 야 니가 김민석이냐? 돈 있어? 돈 없는데요. 야 쟤 몸뒤져. 너 천 원 나올 때마다 얼차려 10분이다. 야 여기 얘 지갑 있는데? 오 지갑만 봐도 돈 많게 생겼네. 열어봐봐 오 12만원 있네? 얼차려가 몇 분이야? 야 이 돈 주면 얼차려 없애줄게. 그거 오늘 저 문제집 사려고 가져온 돈이라. 혹시 내일 드리면 안될까요? 야 니 얼차려 받고 싶냐? 그렇게 내일 주고 싶으면 오늘 이 돈도 우리 주고 내일도 돈 가져다 주면 돼. 뭐가 어려워. 네 알겠습니다. 그 12만원 가져게세요. 말 잘 듣네. 아주 예뻐 내일도 돈 가져와라. 안 그러면 알지? 내일도 같은 시간에 여기로 와.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "9d530cda",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input: 김인턴 지금 회의 들어가야 되니까 빨리 이거 좀 해와. 아 저 지금 퇴근하려고 했는데요 야 김인턴. 너 정규직 되기 싫어? 아뇨 되고 싶습니다 근데 행동거지가 그따구야? 죄송합니다 너 전환되는거 내 입김 쎈거 몰라서 지금 말대꾸야? 빨리 해와 알았어? 알겠습니다 너 한 번만 더 그래봐 진짜. 죄송합니다.\n",
      "Output: 직장 내 괴롭힘 대화\n"
     ]
    }
   ],
   "source": [
    "output = predict('김인턴 지금 회의 들어가야 되니까 빨리 이거 좀 해와. 아 저 지금 퇴근하려고 했는데요 야 김인턴. 너 정규직 되기 싫어? 아뇨 되고 싶습니다 근데 행동거지가 그따구야? 죄송합니다 너 전환되는거 내 입김 쎈거 몰라서 지금 말대꾸야? 빨리 해와 알았어? 알겠습니다 너 한 번만 더 그래봐 진짜. 죄송합니다.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "88f8b16e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input: 안녕하세요 저는 이번에 새로온 알바생입니다 반가워요 서브웨이 알바는 처음이죠 네 빵집 아르바이트는 해봤는데 서브웨이는 처음이네요 별거 없고 비슷해요 포스는 해봤어요 네 많이 해봤어요 그러면 빵 종류랑 레시피만 설명드릴게요 감사합니다 혹시 메일주소 알려줄래요 레시피 보내드릴게요 문자로 보내드릴게요 고마워요 네 잘 부탁드려요\n",
      "Output: 직장 내 괴롭힘 대화\n"
     ]
    }
   ],
   "source": [
    "output = predict('안녕하세요 저는 이번에 새로온 알바생입니다 반가워요 서브웨이 알바는 처음이죠 네 빵집 아르바이트는 해봤는데 서브웨이는 처음이네요 별거 없고 비슷해요 포스는 해봤어요 네 많이 해봤어요 그러면 빵 종류랑 레시피만 설명드릴게요 감사합니다 혹시 메일주소 알려줄래요 레시피 보내드릴게요 문자로 보내드릴게요 고마워요 네 잘 부탁드려요')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "128af357",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input: 흑흑 나 도저히 못찾아 찾아줘 거봐 디자이너들이 생각이없다니까 중국인들이 최고야 중국인좀데려다가 좋은원단으로좀 만들어주지 엠제이드사지마 물론돈없어아직 웅사지마 가방필요한데어떡해 잘좀찾아보 정말없지만 찾고말겠어 말일까지 찾아 없지만 퉁\n",
      "Output: 직장 내 괴롭힘 대화\n"
     ]
    }
   ],
   "source": [
    "output = predict('흑흑 나 도저히 못찾아 찾아줘 거봐 디자이너들이 생각이없다니까 중국인들이 최고야 중국인좀데려다가 좋은원단으로좀 만들어주지 엠제이드사지마 물론돈없어아직 웅사지마 가방필요한데어떡해 잘좀찾아보 정말없지만 찾고말겠어 말일까지 찾아 없지만 퉁')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "da33b6c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input: 빠끄 뭐해 빠끄빠끄 거려 염따형 모르냐 몰라 그게 누군데 랩퍼이자 유튜버 재밌어 관심없다 빠끄 아 제발 알았어 안할게 빠끄 꺼져 쫌\n",
      "Output: 직장 내 괴롭힘 대화\n"
     ]
    }
   ],
   "source": [
    "output = predict('빠끄 뭐해 빠끄빠끄 거려 염따형 모르냐 몰라 그게 누군데 랩퍼이자 유튜버 재밌어 관심없다 빠끄 아 제발 알았어 안할게 빠끄 꺼져 쫌')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14fc132d",
   "metadata": {},
   "source": [
    "#### 위에건 일반 대화 아닌가? 애매함ㅎ. 2 epochs에서는 일반 대화로 분류함"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "1e0056f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input: 국희씨 네? 이번주말에 뭐해? 애들이랑 키즈카페 가기러했어요 어 사실 나도 아까 점심먹을때 들어서 알고 있었는데 확인차 물어봤어 왜그러세요? 응 우리애들이랑 국희씨 애들이랑 나이도 얼추 비슷한데 주말에 키즈카페 좀 데려가주라 네?? 실장님은 안가시구요? 어 나는 집도 좀 치우고 밀린 일좀 보게 부탁할게 하지만 제가 애들 4명이나 보기엔 우리애들 얌전하니까 너무걱정마 내가 주의줄게 그럼 주말에 우리집앞으로 와\n",
      "Output: 직장 내 괴롭힘 대화\n"
     ]
    }
   ],
   "source": [
    "output = predict('국희씨 네? 이번주말에 뭐해? 애들이랑 키즈카페 가기러했어요 어 사실 나도 아까 점심먹을때 들어서 알고 있었는데 확인차 물어봤어 왜그러세요? 응 우리애들이랑 국희씨 애들이랑 나이도 얼추 비슷한데 주말에 키즈카페 좀 데려가주라 네?? 실장님은 안가시구요? 어 나는 집도 좀 치우고 밀린 일좀 보게 부탁할게 하지만 제가 애들 4명이나 보기엔 우리애들 얌전하니까 너무걱정마 내가 주의줄게 그럼 주말에 우리집앞으로 와')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "2c008601",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input: 저기요 제가 파워블로거에 맘카페까지 활동하고 있어요.  아.네. 멋지시네요!!!! 파워블로거 분들이 쓰신글을 조금 믿음이 가더라구요. 그쵸? 와 된장찌개 진짜 잘 먹었어요. 요리 솜씨가 좋네요 이만 가보겠습니다. 저기요 손님 밥 값 지불 안 하셨는데요! 네? 저 파워블로거라니까요? 제가 홍보해드릴건데 밥은 무료로 주셔야죠 저 홍보해달라고 한 적 없는데요 와서 빨리 밥값내고 가세요. 저 홍보해달라고 한 적 없어요. 그렇게 말 번복하시면 안되죠. 엄연한 계약 사항인데. 제가 언제리뷰해달라고 했어요 그냥 멋지시다고 했죠 빨리 돈내고 가세요. 나참 어이가 없네 아주 안 좋게 적을거니까 각오하세요. 하. 그냥 돈 내지말고 가세요. 그냥 가셔도 됩니다.\n",
      "Output: 직장 내 괴롭힘 대화\n"
     ]
    }
   ],
   "source": [
    "output = predict('저기요 제가 파워블로거에 맘카페까지 활동하고 있어요.  아.네. 멋지시네요!!!! 파워블로거 분들이 쓰신글을 조금 믿음이 가더라구요. 그쵸? 와 된장찌개 진짜 잘 먹었어요. 요리 솜씨가 좋네요 이만 가보겠습니다. 저기요 손님 밥 값 지불 안 하셨는데요! 네? 저 파워블로거라니까요? 제가 홍보해드릴건데 밥은 무료로 주셔야죠 저 홍보해달라고 한 적 없는데요 와서 빨리 밥값내고 가세요. 저 홍보해달라고 한 적 없어요. 그렇게 말 번복하시면 안되죠. 엄연한 계약 사항인데. 제가 언제리뷰해달라고 했어요 그냥 멋지시다고 했죠 빨리 돈내고 가세요. 나참 어이가 없네 아주 안 좋게 적을거니까 각오하세요. 하. 그냥 돈 내지말고 가세요. 그냥 가셔도 됩니다.')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "596c18bf",
   "metadata": {},
   "source": [
    "# 하이퍼파라미터 간 실험"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0df2a1b9",
   "metadata": {},
   "source": [
    "### 1. Max length값 120->100 감소 시키기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "92ce4703",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 샘플의 최대 허용 길이 또는 패딩 후의 최종 길이\n",
    "MAX_LENGTH = 100\n",
    "\n",
    "BATCH_SIZE = 64\n",
    "BUFFER_SIZE = 20000\n",
    "\n",
    "# 디코더는 이전의 target을 다음의 input으로 사용합니다.\n",
    "# 이에 따라 outputs에서는 START_TOKEN을 제거하겠습니다.\n",
    "dataset = tf.data.Dataset.from_tensor_slices((\n",
    "    {\n",
    "        'inputs': conversation,\n",
    "        'dec_inputs': class_label[:, :-1]\n",
    "    },\n",
    "    {\n",
    "        'outputs': class_label[:, 1:]\n",
    "    },\n",
    "))\n",
    "\n",
    "dataset = dataset.cache()\n",
    "dataset = dataset.shuffle(BUFFER_SIZE)\n",
    "dataset = dataset.batch(BATCH_SIZE)\n",
    "dataset = dataset.prefetch(tf.data.experimental.AUTOTUNE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "b96607d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"transformer\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "inputs (InputLayer)             [(None, None)]       0                                            \n",
      "__________________________________________________________________________________________________\n",
      "dec_inputs (InputLayer)         [(None, None)]       0                                            \n",
      "__________________________________________________________________________________________________\n",
      "enc_padding_mask (Lambda)       (None, 1, 1, None)   0           inputs[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "encoder (Functional)            (None, None, 256)    5187072     inputs[0][0]                     \n",
      "                                                                 enc_padding_mask[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "look_ahead_mask (Lambda)        (None, 1, None, None 0           dec_inputs[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dec_padding_mask (Lambda)       (None, 1, 1, None)   0           inputs[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "decoder (Functional)            (None, None, 256)    5775872     dec_inputs[0][0]                 \n",
      "                                                                 encoder[0][0]                    \n",
      "                                                                 look_ahead_mask[0][0]            \n",
      "                                                                 dec_padding_mask[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "outputs (Dense)                 (None, None, 16144)  4149008     decoder[0][0]                    \n",
      "==================================================================================================\n",
      "Total params: 15,111,952\n",
      "Trainable params: 15,111,952\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "Epoch 1/9\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "in user code:\n\n    /opt/conda/lib/python3.9/site-packages/keras/engine/training.py:853 train_function  *\n        return step_function(self, iterator)\n    /tmp/ipykernel_347/3646571114.py:8 accuracy  *\n        return tf.keras.metrics.sparse_categorical_accuracy(y_true, y_pred)\n    /opt/conda/lib/python3.9/site-packages/tensorflow/python/util/dispatch.py:206 wrapper  **\n        return target(*args, **kwargs)\n    /opt/conda/lib/python3.9/site-packages/keras/metrics.py:3537 sparse_categorical_accuracy\n        return tf.cast(tf.equal(y_true, y_pred), backend.floatx())\n    /opt/conda/lib/python3.9/site-packages/tensorflow/python/util/dispatch.py:206 wrapper\n        return target(*args, **kwargs)\n    /opt/conda/lib/python3.9/site-packages/tensorflow/python/ops/math_ops.py:1864 equal\n        return gen_math_ops.equal(x, y, name=name)\n    /opt/conda/lib/python3.9/site-packages/tensorflow/python/ops/gen_math_ops.py:3217 equal\n        _, _, _op, _outputs = _op_def_library._apply_op_helper(\n    /opt/conda/lib/python3.9/site-packages/tensorflow/python/framework/op_def_library.py:748 _apply_op_helper\n        op = g._create_op_internal(op_type_name, inputs, dtypes=None,\n    /opt/conda/lib/python3.9/site-packages/tensorflow/python/framework/func_graph.py:599 _create_op_internal\n        return super(FuncGraph, self)._create_op_internal(  # pylint: disable=protected-access\n    /opt/conda/lib/python3.9/site-packages/tensorflow/python/framework/ops.py:3561 _create_op_internal\n        ret = Operation(\n    /opt/conda/lib/python3.9/site-packages/tensorflow/python/framework/ops.py:2041 __init__\n        self._c_op = _create_c_op(self._graph, node_def, inputs,\n    /opt/conda/lib/python3.9/site-packages/tensorflow/python/framework/ops.py:1883 _create_c_op\n        raise ValueError(str(e))\n\n    ValueError: Dimensions must be equal, but are 99 and 119 for '{{node Equal}} = Equal[T=DT_FLOAT, incompatible_shape_error=true](Reshape, Cast_2)' with input shapes: [?,99], [?,119].\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_347/406747255.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     29\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m \u001b[0;31m# epochs를 9으로 설정하고 모델을 학습합니다.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 31\u001b[0;31m \u001b[0mhistory\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/opt/conda/lib/python3.9/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1182\u001b[0m                 _r=1):\n\u001b[1;32m   1183\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1184\u001b[0;31m               \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1185\u001b[0m               \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1186\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.9/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    883\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    884\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jit_compile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 885\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    886\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    887\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.9/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    931\u001b[0m       \u001b[0;31m# This is the first call of __call__, so we have to initialize.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    932\u001b[0m       \u001b[0minitializers\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 933\u001b[0;31m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_initialize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0madd_initializers_to\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minitializers\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    934\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    935\u001b[0m       \u001b[0;31m# At this point we know that the initialization is complete (or less\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.9/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_initialize\u001b[0;34m(self, args, kwds, add_initializers_to)\u001b[0m\n\u001b[1;32m    757\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_graph_deleter\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mFunctionDeleter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lifted_initializer_graph\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    758\u001b[0m     self._concrete_stateful_fn = (\n\u001b[0;32m--> 759\u001b[0;31m         self._stateful_fn._get_concrete_function_internal_garbage_collected(  # pylint: disable=protected-access\n\u001b[0m\u001b[1;32m    760\u001b[0m             *args, **kwds))\n\u001b[1;32m    761\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.9/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_get_concrete_function_internal_garbage_collected\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   3064\u001b[0m       \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3065\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3066\u001b[0;31m       \u001b[0mgraph_function\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_define_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3067\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3068\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.9/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_maybe_define_function\u001b[0;34m(self, args, kwargs)\u001b[0m\n\u001b[1;32m   3461\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3462\u001b[0m           \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_function_cache\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmissed\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcall_context_key\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3463\u001b[0;31m           \u001b[0mgraph_function\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_create_graph_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3464\u001b[0m           \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_function_cache\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprimary\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcache_key\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3465\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.9/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_create_graph_function\u001b[0;34m(self, args, kwargs, override_flat_arg_shapes)\u001b[0m\n\u001b[1;32m   3296\u001b[0m     \u001b[0marg_names\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbase_arg_names\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mmissing_arg_names\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3297\u001b[0m     graph_function = ConcreteFunction(\n\u001b[0;32m-> 3298\u001b[0;31m         func_graph_module.func_graph_from_py_func(\n\u001b[0m\u001b[1;32m   3299\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_name\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3300\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_python_function\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.9/site-packages/tensorflow/python/framework/func_graph.py\u001b[0m in \u001b[0;36mfunc_graph_from_py_func\u001b[0;34m(name, python_func, args, kwargs, signature, func_graph, autograph, autograph_options, add_control_dependencies, arg_names, op_return_value, collections, capture_by_value, override_flat_arg_shapes, acd_record_initial_resource_uses)\u001b[0m\n\u001b[1;32m   1005\u001b[0m         \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moriginal_func\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_decorator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munwrap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpython_func\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1006\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1007\u001b[0;31m       \u001b[0mfunc_outputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpython_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mfunc_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfunc_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1008\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1009\u001b[0m       \u001b[0;31m# invariant: `func_outputs` contains only Tensors, CompositeTensors,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.9/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36mwrapped_fn\u001b[0;34m(*args, **kwds)\u001b[0m\n\u001b[1;32m    666\u001b[0m         \u001b[0;31m# the function a weak reference to itself to avoid a reference cycle.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    667\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcompile_with_xla\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 668\u001b[0;31m           \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mweak_wrapped_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__wrapped__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    669\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    670\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.9/site-packages/tensorflow/python/framework/func_graph.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    992\u001b[0m           \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint:disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    993\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"ag_error_metadata\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 994\u001b[0;31m               \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mag_error_metadata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_exception\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    995\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    996\u001b[0m               \u001b[0;32mraise\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: in user code:\n\n    /opt/conda/lib/python3.9/site-packages/keras/engine/training.py:853 train_function  *\n        return step_function(self, iterator)\n    /tmp/ipykernel_347/3646571114.py:8 accuracy  *\n        return tf.keras.metrics.sparse_categorical_accuracy(y_true, y_pred)\n    /opt/conda/lib/python3.9/site-packages/tensorflow/python/util/dispatch.py:206 wrapper  **\n        return target(*args, **kwargs)\n    /opt/conda/lib/python3.9/site-packages/keras/metrics.py:3537 sparse_categorical_accuracy\n        return tf.cast(tf.equal(y_true, y_pred), backend.floatx())\n    /opt/conda/lib/python3.9/site-packages/tensorflow/python/util/dispatch.py:206 wrapper\n        return target(*args, **kwargs)\n    /opt/conda/lib/python3.9/site-packages/tensorflow/python/ops/math_ops.py:1864 equal\n        return gen_math_ops.equal(x, y, name=name)\n    /opt/conda/lib/python3.9/site-packages/tensorflow/python/ops/gen_math_ops.py:3217 equal\n        _, _, _op, _outputs = _op_def_library._apply_op_helper(\n    /opt/conda/lib/python3.9/site-packages/tensorflow/python/framework/op_def_library.py:748 _apply_op_helper\n        op = g._create_op_internal(op_type_name, inputs, dtypes=None,\n    /opt/conda/lib/python3.9/site-packages/tensorflow/python/framework/func_graph.py:599 _create_op_internal\n        return super(FuncGraph, self)._create_op_internal(  # pylint: disable=protected-access\n    /opt/conda/lib/python3.9/site-packages/tensorflow/python/framework/ops.py:3561 _create_op_internal\n        ret = Operation(\n    /opt/conda/lib/python3.9/site-packages/tensorflow/python/framework/ops.py:2041 __init__\n        self._c_op = _create_c_op(self._graph, node_def, inputs,\n    /opt/conda/lib/python3.9/site-packages/tensorflow/python/framework/ops.py:1883 _create_c_op\n        raise ValueError(str(e))\n\n    ValueError: Dimensions must be equal, but are 99 and 119 for '{{node Equal}} = Equal[T=DT_FLOAT, incompatible_shape_error=true](Reshape, Cast_2)' with input shapes: [?,99], [?,119].\n"
     ]
    }
   ],
   "source": [
    "tf.keras.backend.clear_session()\n",
    "\n",
    "# 하이퍼파라미터\n",
    "NUM_LAYERS = 2 # 인코더와 디코더의 층의 개수\n",
    "D_MODEL = 256 # 인코더와 디코더 내부의 입, 출력의 고정 차원\n",
    "NUM_HEADS = 8 # 멀티 헤드 어텐션에서의 헤드 수 \n",
    "UNITS = 512 # 피드 포워드 신경망의 은닉층의 크기\n",
    "DROPOUT = 0.05 # 드롭아웃의 비율\n",
    "\n",
    "model = transformer(\n",
    "    vocab_size=VOCAB_SIZE,\n",
    "    num_layers=NUM_LAYERS,\n",
    "    units=UNITS,\n",
    "    d_model=D_MODEL,\n",
    "    num_heads=NUM_HEADS,\n",
    "    dropout=DROPOUT)\n",
    "\n",
    "model.summary()\n",
    "\n",
    "learning_rate = CustomSchedule(D_MODEL)\n",
    "\n",
    "optimizer = tf.keras.optimizers.Adam(\n",
    "    learning_rate, beta_1=0.9, beta_2=0.98, epsilon=1e-9)\n",
    "\n",
    "model.compile(optimizer=optimizer, loss=loss_function, metrics=[accuracy])\n",
    "\n",
    "epochs = 9\n",
    "\n",
    "\n",
    "# epochs를 9으로 설정하고 모델을 학습합니다.\n",
    "history = model.fit(dataset, epochs=epochs, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d8c1c1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 손실 값 그래프\n",
    "plt.figure(figsize=(12, 6))\n",
    "\n",
    "# Loss 그래프\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(history.history['loss'], label='Training Loss')\n",
    "plt.title('Training Loss')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "\n",
    "# 정확도 그래프\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(history.history['accuracy'], label='Training Accuracy')\n",
    "plt.title('Training Accuracy')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87133aca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 회고\n",
    "[Positional Encoding]\n",
    "positional encoding을 gpt-1처럼 embedding으로 변경하면 어떻게 될까?\n",
    "transformer에서 주로 positional encoding보다 embedding이 더 성능이 잘 나올 것 같은데(단어 간의 의미 관계를 유의미한 벡터의 거리로 표현했기 때문) encoding이 주로 사용되는 이유가 embedding보다 데이터 소모 가성비가 좋아서일까?\n",
    "\n",
    "[토크나이징 - 형태소 분석기/subwordtovector]\n",
    "한국어 데이터에 주로 사용되는 형태소 분석기를 사용하여 토크나이징을 하면 성능이 어떻게 될까?\n",
    "\n",
    "[Max length값]\n",
    "사분위 값인 120을 기준으로 100 or 140 에서의 성능?\n",
    "\n",
    "[dropout 값]\n",
    "0.01 -> (0.05) -> 0.10 비교\n",
    "\n",
    "[batch size와 buffer size]\n",
    "1) epochs 수와 batch size의 관계?\n",
    "2) batch size와 buffer size의 관계?\n",
    "\n",
    "[epochs]\n",
    "early stopping을 통해 최적의 epochs 수 확인\n",
    "\n",
    "[Num_LAYERS] \n",
    "인코더와 디코더의 층의 개수를 증가시킨다면?\n",
    "(2) -> 4 -> 8 -> 12\n",
    "\n",
    "[실험 수업 때 했던 파라미터 최적화 기능?]\n",
    "위 기능을 사용하면 여러번 실험을 하지 않아도 파라미터 별 영향도 및 최적값을 도출해줄까? 시간을 아낄 수 있을 것 같다\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
